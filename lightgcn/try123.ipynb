{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import sys\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy.sparse as sp\n",
    "from time import time\n",
    "import dgl\n",
    "import mxnet as mx\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataload():\n",
    "    train_file = \"./gowalla/train.txt\"\n",
    "    test_file = \"./gowalla/test.txt\"\n",
    "    m_item = 0\n",
    "    n_user = 0\n",
    "    trainUniqueUsers, trainItem, trainUser = [], [], []\n",
    "    testUniqueUsers, testItem, testUser = [], [], []\n",
    "    with open(train_file) as f:\n",
    "        for l in f.readlines():\n",
    "            if len(l) > 0:\n",
    "                l = l.strip('\\n').split(' ')\n",
    "                items = [int(i) for i in l[1:]]\n",
    "                uid = int(l[0])\n",
    "                trainUniqueUsers.append(uid)\n",
    "                trainUser.extend([uid] * len(items))\n",
    "                trainItem.extend(items)\n",
    "                m_item = max(m_item, max(items))\n",
    "                n_user = max(n_user, uid)\n",
    "    trainUniqueUsers = np.array(trainUniqueUsers)\n",
    "    trainUser = np.array(trainUser)\n",
    "    trainItem = np.array(trainItem)\n",
    "    return trainUser,trainItem,trainUniqueUsers\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainUser,trainItem,trainUniqueUsers = dataload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getgraph(trainUser,trainItem):\n",
    "    g = dgl.heterograph({('user', 'edg' , 'item'): (trainUser, trainItem),\n",
    "                         ('item', 'edg', 'user'): (trainItem,trainUser)})\n",
    "    embedding_user = torch.nn.Embedding(g.num_nodes('user'),64)\n",
    "    embedding_item = torch.nn.Embedding(g.num_nodes('item'),64)\n",
    "    torch.nn.init.normal_(embedding_user.weight, std=0.1)\n",
    "    torch.nn.init.normal_(embedding_item.weight, std=0.1)\n",
    "    g.nodes['user'].data['emb'] =  embedding_user.weight\n",
    "    g.nodes['item'].data['emb'] =  embedding_item.weight\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Lightgcn(nn.Module):\n",
    "    def __init__(self,\n",
    "                 g,\n",
    "                 n_layers):\n",
    "        self.g = g\n",
    "        self.layers = n_layers\n",
    "        self.__init_weight()\n",
    "        \n",
    "    def __init_weight(self):\n",
    "        self.gre_user = g.out_degrees(etype=('user', 'edg1' , 'item'))\n",
    "        self.gre_item = g.out_degrees(etype=('item', 'edg2' , 'user'))\n",
    "        self.gre_user = gre_user ** (-0.5)\n",
    "        self.gre_user = gre_user.unsqueeze(1).repeat(1,2)\n",
    "        self.gre_item = gre_item  ** (-0.5)\n",
    "        self.gre_item = gre_item.unsqueeze(1).repeat(1,2)\n",
    "\n",
    "    def computer(self):\n",
    "        User = []\n",
    "        Item = []\n",
    "        U.append(g.nodes['user'].data['emb'])\n",
    "        I.append(g.nodes['item'].data['emb'])\n",
    "        for i in range(self.layers):\n",
    "            g.nodes['user'].data['emb'] = torch.mul(g.nodes['user'].data['emb'], self.gre_user)\n",
    "            g.nodes['item'].data['emb'] = torch.mul(g.nodes['item'].data['emb'], self.gre_item)\n",
    "            g.multi_update_all(\n",
    "                {'edg1':(fn.copy_src('emb', 'm'), fn.sum('m', 'emb')),\n",
    "                'edg2':(fn.copy_src('emb', 'm'), fn.sum('m', 'emb'))},\n",
    "                \"sum\"\n",
    "            )\n",
    "            g.nodes['user'].data['emb'] = torch.mul(g.nodes['user'].data['emb'], gre_user)\n",
    "            g.nodes['item'].data['emb'] = torch.mul(g.nodes['item'].data['emb'], gre_item)\n",
    "            U.append(g.nodes['user'].data['emb'])\n",
    "            I.append(g.nodes['item'].data['emb'])\n",
    "        out_user = torch.stack(U,dim=1)\n",
    "        out_user = torch.mean(out_user,dim=1)\n",
    "        out_item = torch.stack(I,dim=1)\n",
    "        out_item = torch.mean(out_item,dim=1)\n",
    "        return out_user, out_item\n",
    "    \n",
    "    def bpr_loss(self)\n",
    "        out_user, out_item = self.computer()\n",
    "        score = torch.mm(out_user, out_item.t())\n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def UniformSample_original(trainUser,trainItem, g):\n",
    "    n_user = g.num_nodes('user')\n",
    "    m_item = g.num_nodes('item')\n",
    "    UserItemNet = csr_matrix((np.ones(len(trainUser)), (trainUser, trainItem)),\n",
    "                                      shape=(n_user, m_item))\n",
    "    total_start = time()\n",
    "    user_num = len(trainUser)\n",
    "    users = np.random.randint(0, n_user, user_num)\n",
    "    S = []\n",
    "    sample_time1 = 0.\n",
    "    sample_time2 = 0.\n",
    "    allPos = []\n",
    "    for user in range(n_user):\n",
    "        allPos.append(UserItemNet[user].nonzero()[1])\n",
    "    for i, user in enumerate(users):\n",
    "        start = time()\n",
    "        posForUser = allPos[user]\n",
    "        if len(posForUser) == 0:\n",
    "            continue\n",
    "        sample_time2 += time() - start\n",
    "        posindex = np.random.randint(0, len(posForUser))\n",
    "        positem = posForUser[posindex]\n",
    "        while True:\n",
    "            negitem = np.random.randint(0, m_item)\n",
    "            if negitem in posForUser:\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "        S.append([user, positem, negitem])\n",
    "        end = time()\n",
    "        sample_time1 += end - start\n",
    "    total = time() - total_start\n",
    "    return np.array(S), [total, sample_time1, sample_time2]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainUser,trainItem,trainUniqueUsers = dataload()\n",
    "g = getgraph(trainUser,trainItem)\n",
    "s, t = UniformSample_original(trainUser,trainItem, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes={'item': 40981, 'user': 29858},\n",
       "      num_edges={('item', 'edg', 'user'): 810128, ('user', 'edg', 'item'): 810128},\n",
       "      metagraph=[('item', 'user', 'edg'), ('user', 'item', 'edg')])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
