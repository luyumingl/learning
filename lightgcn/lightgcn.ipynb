{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import sys\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy.sparse as sp\n",
    "import time\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "import mxnet as mx\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataload():\n",
    "    #train_file = \"./gowalla/example.txt\"\n",
    "    train_file = \"./gowalla/train.txt\"\n",
    "    #test_file = \"./gowalla/test.txt\"\n",
    "    m_item = 0\n",
    "    n_user = 0\n",
    "    trainUniqueUsers, trainItem, trainUser = [], [], []\n",
    "    testUniqueUsers, testItem, testUser = [], [], []\n",
    "    with open(train_file) as f:\n",
    "        for l in f.readlines():\n",
    "            if len(l) > 0:\n",
    "                l = l.strip('\\n').split(' ')\n",
    "                items = [int(i) for i in l[1:]]\n",
    "                uid = int(l[0])\n",
    "                trainUniqueUsers.append(uid)\n",
    "                trainUser.extend([uid] * len(items))\n",
    "                trainItem.extend(items)\n",
    "                m_item = max(m_item, max(items))\n",
    "                n_user = max(n_user, uid)\n",
    "    trainUser = np.array(trainUser)\n",
    "    trainItem = np.array(trainItem)\n",
    "    return trainUser,trainItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getgraph(trainUser,trainItem):\n",
    "    g = dgl.heterograph({('user', 'buy' , 'item'): (trainUser, trainItem),\n",
    "                         ('item', 'attr', 'user'): (trainItem,trainUser)})\n",
    "    gre_user = g.out_degrees(etype=('user', 'buy' , 'item'))\n",
    "    gre_item = g.out_degrees(etype=('item', 'attr' , 'user'))\n",
    "    gre_user = gre_user ** (-0.5)\n",
    "    gre_user = gre_user.unsqueeze(1).repeat(1,64)\n",
    "    gre_item = gre_item  ** (-0.5)\n",
    "    gre_item = gre_item.unsqueeze(1).repeat(1,64)\n",
    "    return g, gre_user, gre_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UniformSample_original(trainUser,trainItem, g):\n",
    "    n_user = g.num_nodes('user')\n",
    "    m_item = g.num_nodes('item')\n",
    "    UserItemNet = csr_matrix((np.ones(len(trainUser)), (trainUser, trainItem)),\n",
    "                                      shape=(n_user, m_item))\n",
    "    total_start = time.time()\n",
    "    user_num = len(trainUser)\n",
    "    users = np.random.randint(0, n_user, user_num)\n",
    "    S = []\n",
    "    sample_time1 = 0.\n",
    "    sample_time2 = 0.\n",
    "    allPos = []\n",
    "    for user in range(n_user):\n",
    "        allPos.append(UserItemNet[user].nonzero()[1])\n",
    "    for i, user in enumerate(users):\n",
    "        posForUser = allPos[user]\n",
    "        if len(posForUser) == 0:\n",
    "            continue\n",
    "        posindex = np.random.randint(0, len(posForUser))\n",
    "        positem = posForUser[posindex]\n",
    "        while True:\n",
    "            negitem = np.random.randint(0, m_item)\n",
    "            if negitem in posForUser:\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "        S.append([user, positem, negitem])\n",
    "\n",
    "    total = time.time() - total_start\n",
    "    print(\"time:{}\".format(total))\n",
    "    return np.array(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:8.541903734207153\n"
     ]
    }
   ],
   "source": [
    "trainUser,trainItem= dataload()\n",
    "g, gre_user, gre_item= getgraph(trainUser,trainItem)\n",
    "sampling = UniformSample_original(trainUser,trainItem, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lightgcn(nn.Module):\n",
    "    def __init__(self,\n",
    "                g,\n",
    "                gre_user,\n",
    "                gre_item,\n",
    "                n_layers):\n",
    "        super(Lightgcn, self).__init__()\n",
    "        self.g = g\n",
    "        self.gre_user = gre_user\n",
    "        self.gre_item = gre_item\n",
    "        self.layers = n_layers\n",
    "        self.num_users = g.num_nodes('user')\n",
    "        self.num_items = g.num_nodes('item')\n",
    "        self. __init_weight()\n",
    "    def __init_weight(self):\n",
    "        self.embedding_user = torch.nn.Embedding(\n",
    "            num_embeddings=self.num_users, embedding_dim=64)\n",
    "        self.embedding_item = torch.nn.Embedding(\n",
    "            num_embeddings=self.num_items, embedding_dim=64)\n",
    "\n",
    "    def computer(self):\n",
    "        U= []\n",
    "        I = []\n",
    "        U.append(self.embedding_user.weight)\n",
    "        I.append(self.embedding_item.weight)\n",
    "        g.nodes['user'].data['emb'] = self.embedding_user.weight\n",
    "        g.nodes['item'].data['emb'] = self.embedding_item.weight\n",
    "        for i in range(self.layers):\n",
    "            g.nodes['user'].data['emb'] = torch.mul(g.nodes['user'].data['emb'], self.gre_user)\n",
    "            g.nodes['item'].data['emb'] = torch.mul(g.nodes['item'].data['emb'], self.gre_item)\n",
    "            g.multi_update_all(\n",
    "                {'buy':(fn.copy_u('emb', 'm'), fn.sum('m', 'neigh')),\n",
    "                'attr':(fn.copy_u('emb', 'm'), fn.sum('m', 'neigh'))},\n",
    "                \"sum\"\n",
    "            )\n",
    "            user_out = g.nodes['user'].data['neigh']\n",
    "            item_out = g.nodes['item'].data['neigh']\n",
    "            user_out = torch.mul(user_out, gre_user)\n",
    "            item_out = torch.mul(item_out, gre_item)\n",
    "            U.append(user_out)\n",
    "            I.append(item_out)\n",
    "        res_user = torch.stack(U,dim=1)\n",
    "        res_user = torch.mean(res_user,dim=1)\n",
    "        res_item = torch.stack(I,dim=1)\n",
    "        res_item = torch.mean(res_item,dim=1)\n",
    "        return res_user, res_item\n",
    "    \n",
    "    def bpr_loss(self, sampling, weight_decay):\n",
    "        out_user, out_item = self.computer()\n",
    "        score = torch.mm(out_user, out_item.t())\n",
    "        #loss = torch.zeros(0)\n",
    "        loss = 0\n",
    "        for s in sampling:\n",
    "            y_ui = score[s[0]][s[1]]\n",
    "            y_uj = score[s[0]][s[2]]\n",
    "            deta_y = nn.functional.softplus(y_ui - y_uj)\n",
    "            loss -=  torch.log(deta_y)\n",
    "        reg_loss = (out_user.norm(2).pow(2) + out_item.norm(2).pow(2)) * 0.5 / len(out_user)\n",
    "        loss = loss + reg_loss * weight_decay\n",
    "        loss = loss / len(sampling)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainUser,trainItem,g,weight_decay,sampling):\n",
    "    print(123)\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        t0 = time.time()\n",
    "        loss = model.bpr_loss(sampling, weight_decay)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t1 = time.time()\n",
    "        print(\"Epoch {:05d} |Loss {:.4f} | Time(s) {:.4f} | \".format(epoch,loss.item(), t1-t0 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "weight_decay = 1e-4\n",
    "n_layers = 3\n",
    "model = Lightgcn(g,\n",
    "                 gre_user,\n",
    "                 gre_item,\n",
    "                 n_layers)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "train(trainUser,trainItem,g,weight_decay,sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
