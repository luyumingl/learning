{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import sys\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.sparse import csr_matrix\n",
    "import scipy.sparse as sp\n",
    "import time\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "import mxnet as mx\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataload():\n",
    "    train_file = \"./gowalla/train.txt\"\n",
    "    test_file = \"./gowalla/test.txt\"\n",
    "    m_item = 0\n",
    "    n_user = 0\n",
    "    trainUniqueUsers, trainItem, trainUser = [], [], []\n",
    "    testUniqueUsers, testItem, testUser = [], [], []\n",
    "    with open(train_file) as f:\n",
    "        for l in f.readlines():\n",
    "            if len(l) > 0:\n",
    "                l = l.strip('\\n').split(' ')\n",
    "                items = [int(i) for i in l[1:]]\n",
    "                uid = int(l[0])\n",
    "                trainUniqueUsers.append(uid)\n",
    "                trainUser.extend([uid] * len(items))\n",
    "                trainItem.extend(items)\n",
    "                m_item = max(m_item, max(items))\n",
    "                n_user = max(n_user, uid)\n",
    "    trainUser = np.array(trainUser)\n",
    "    trainItem = np.array(trainItem)\n",
    "    return trainUser,trainItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getgraph(trainUser,trainItem):\n",
    "    g = dgl.heterograph({('user', 'like' , 'item'): (trainUser, trainItem),\n",
    "                         ('item', 'good', 'user'): (trainItem,trainUser)})\n",
    "    gre_user = g.out_degrees(etype=('user', 'like' , 'item'))\n",
    "    gre_item = g.out_degrees(etype=('item', 'good' , 'user'))\n",
    "    gre_user = gre_user ** (-0.5)\n",
    "    gre_user = gre_user.unsqueeze(1).repeat(1,64)\n",
    "    gre_item = gre_item  ** (-0.5)\n",
    "    gre_item = gre_item.unsqueeze(1).repeat(1,64)\n",
    "    return g, gre_user, gre_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainUser,trainItem= dataload()\n",
    "g, gre_user, gre_item= getgraph(trainUser,trainItem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-85b96e9d65e7>, line 44)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-85b96e9d65e7>\"\u001b[1;36m, line \u001b[1;32m44\u001b[0m\n\u001b[1;33m    def bpr_loss(self)\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class Lightgcn(nn.Module):\n",
    "    def __init__(self,\n",
    "                g,\n",
    "                gre_user,\n",
    "                gre_item,\n",
    "                n_layers):\n",
    "        super(Lightgcn, self).__init__()\n",
    "        self.g = g\n",
    "        self.gre_user = gre_user\n",
    "        self.gre_item = gre_item\n",
    "        self.layers = n_layers\n",
    "        self.num_users = g.num_nodes('user')\n",
    "        self.num_items = g.num_nodes('item')\n",
    "        self.__init_weight()\n",
    "    def __init_weight(self):\n",
    "        self.embedding_user = torch.nn.Embedding(\n",
    "            num_embeddings=self.num_users, embedding_dim=self.latent_dim)\n",
    "        self.embedding_item = torch.nn.Embedding(\n",
    "            num_embeddings=self.num_items, embedding_dim=self.latent_dim)\n",
    "    \n",
    "    def computer(self):\n",
    "        User = []\n",
    "        Item = []\n",
    "        U.append(g.nodes['user'].data['emb'])\n",
    "        I.append(g.nodes['item'].data['emb'])\n",
    "        for i in range(self.layers):\n",
    "            g.nodes['user'].data['emb'] = torch.mul(g.nodes['user'].data['emb'], self.gre_user)\n",
    "            g.nodes['item'].data['emb'] = torch.mul(g.nodes['item'].data['emb'], self.gre_item)\n",
    "            g.multi_update_all(\n",
    "                {'edg1':(fn.copy_src('emb', 'm'), fn.sum('m', 'emb')),\n",
    "                'edg2':(fn.copy_src('emb', 'm'), fn.sum('m', 'emb'))},\n",
    "                \"sum\"\n",
    "            )\n",
    "            g.nodes['user'].data['emb'] = torch.mul(g.nodes['user'].data['emb'], gre_user)\n",
    "            g.nodes['item'].data['emb'] = torch.mul(g.nodes['item'].data['emb'], gre_item)\n",
    "            U.append(g.nodes['user'].data['emb'])\n",
    "            I.append(g.nodes['item'].data['emb'])\n",
    "        out_user = torch.stack(U,dim=1)\n",
    "        out_user = torch.mean(out_user,dim=1)\n",
    "        out_item = torch.stack(I,dim=1)\n",
    "        out_item = torch.mean(out_item,dim=1)\n",
    "        return out_user, out_item\n",
    "    \n",
    "    def bpr_loss(self)\n",
    "        out_user, out_item = self.computer()\n",
    "        score = torch.mm(out_user, out_item.t())\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UniformSample_original(trainUser,trainItem, g):\n",
    "    n_user = g.num_nodes('user')\n",
    "    m_item = g.num_nodes('item')\n",
    "    UserItemNet = csr_matrix((np.ones(len(trainUser)), (trainUser, trainItem)),\n",
    "                                      shape=(n_user, m_item))\n",
    "    total_start = time()\n",
    "    user_num = len(trainUser)\n",
    "    users = np.random.randint(0, n_user, user_num)\n",
    "    S = []\n",
    "    sample_time1 = 0.\n",
    "    sample_time2 = 0.\n",
    "    allPos = []\n",
    "    for user in range(n_user):\n",
    "        allPos.append(UserItemNet[user].nonzero()[1])\n",
    "    for i, user in enumerate(users):\n",
    "        start = time()\n",
    "        posForUser = allPos[user]\n",
    "        if len(posForUser) == 0:\n",
    "            continue\n",
    "        sample_time2 += time() - start\n",
    "        posindex = np.random.randint(0, len(posForUser))\n",
    "        positem = posForUser[posindex]\n",
    "        while True:\n",
    "            negitem = np.random.randint(0, m_item)\n",
    "            if negitem in posForUser:\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "        S.append([user, positem, negitem])\n",
    "        end = time()\n",
    "        sample_time1 += end - start\n",
    "    total = time() - total_start\n",
    "    return np.array(S), [total, sample_time1, sample_time2]\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
